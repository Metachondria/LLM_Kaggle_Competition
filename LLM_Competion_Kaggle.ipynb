{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 86518,
          "databundleVersionId": 9809560,
          "sourceType": "competition"
        },
        {
          "sourceId": 10314385,
          "sourceType": "datasetVersion",
          "datasetId": 6385413
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "LLM Competion Kaggle",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Metachondria/LLM_Kaggle_Competition/blob/main/LLM_Competion_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:37:58.567545Z",
          "iopub.execute_input": "2024-12-29T13:37:58.567848Z",
          "iopub.status.idle": "2024-12-29T13:38:05.345317Z",
          "shell.execute_reply.started": "2024-12-29T13:37:58.567824Z",
          "shell.execute_reply": "2024-12-29T13:38:05.344664Z"
        },
        "id": "6cvcYw5lG_7M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:05.346211Z",
          "iopub.execute_input": "2024-12-29T13:38:05.346547Z",
          "iopub.status.idle": "2024-12-29T13:38:08.79122Z",
          "shell.execute_reply.started": "2024-12-29T13:38:05.346527Z",
          "shell.execute_reply": "2024-12-29T13:38:08.79017Z"
        },
        "id": "JNDarX9LG_7N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:08.793256Z",
          "iopub.execute_input": "2024-12-29T13:38:08.793611Z",
          "iopub.status.idle": "2024-12-29T13:38:08.809883Z",
          "shell.execute_reply.started": "2024-12-29T13:38:08.79358Z",
          "shell.execute_reply": "2024-12-29T13:38:08.809244Z"
        },
        "id": "laKIAprJG_7O",
        "outputId": "01638d49-23c1-42a7-ac5c-773663081a3b"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       id             model_a              model_b  \\\n0   30192  gpt-4-1106-preview           gpt-4-0613   \n1   53567           koala-13b           gpt-4-0613   \n2   65089  gpt-3.5-turbo-0613       mistral-medium   \n3   96401    llama-2-13b-chat  mistral-7b-instruct   \n4  198779           koala-13b   gpt-3.5-turbo-0314   \n\n                                              prompt  \\\n0  [\"Is it morally right to try to have a certain...   \n1  [\"What is the difference between marriage lice...   \n2  [\"explain function calling. how would you call...   \n3  [\"How can I create a test set for a very rare ...   \n4  [\"What is the best way to travel from Tel-Aviv...   \n\n                                          response_a  \\\n0  [\"The question of whether it is morally right ...   \n1  [\"A marriage license is a legal document that ...   \n2  [\"Function calling is the process of invoking ...   \n3  [\"Creating a test set for a very rare category...   \n4  [\"The best way to travel from Tel Aviv to Jeru...   \n\n                                          response_b  winner_model_a  \\\n0  [\"As an AI, I don't have personal beliefs or o...               1   \n1  [\"A marriage license and a marriage certificat...               0   \n2  [\"Function calling is the process of invoking ...               0   \n3  [\"When building a classifier for a very rare c...               1   \n4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n\n   winner_model_b  winner_tie  \n0               0           0  \n1               1           0  \n2               0           1  \n3               0           0  \n4               1           0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:08.81069Z",
          "iopub.execute_input": "2024-12-29T13:38:08.810929Z",
          "iopub.status.idle": "2024-12-29T13:38:08.861202Z",
          "shell.execute_reply.started": "2024-12-29T13:38:08.810905Z",
          "shell.execute_reply": "2024-12-29T13:38:08.860388Z"
        },
        "id": "LGAHbXmXG_7P",
        "outputId": "60658228-ef58-4c18-eed0-57080f35dbea"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "SV4oG7dSG_7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(\"[^a-zA-Z0-9\\s]\", '', text)\n",
        "    doc = nlp(text)\n",
        "    text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct ])\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:08.862032Z",
          "iopub.execute_input": "2024-12-29T13:38:08.86228Z",
          "iopub.status.idle": "2024-12-29T13:38:09.572187Z",
          "shell.execute_reply.started": "2024-12-29T13:38:08.86226Z",
          "shell.execute_reply": "2024-12-29T13:38:09.571475Z"
        },
        "id": "68qTCOQxG_7R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.prompt = train_data.prompt.apply(lambda x: clean_text(x))\n",
        "train_data.response_a = train_data.response_a.apply(lambda x: clean_text(x))\n",
        "train_data.response_b = train_data.response_b.apply(lambda x: clean_text(x))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hru5Cjo3G_7R"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv('processed_train_data.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "--t02U38G_7S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:42.679483Z",
          "iopub.execute_input": "2024-12-29T13:38:42.679818Z",
          "iopub.status.idle": "2024-12-29T13:38:43.611623Z",
          "shell.execute_reply.started": "2024-12-29T13:38:42.679787Z",
          "shell.execute_reply": "2024-12-29T13:38:43.610697Z"
        },
        "id": "whxOKow2G_7S",
        "outputId": "75a0c79c-8f12-4269-bb02-b01698a2eb72",
        "colab": {
          "referenced_widgets": [
            "a5d297b7823145188a476c7d9c20b073",
            "e6bc89f0227f47f59bcd31a8f3b866f8",
            "9b7d7a7e00cb42e8b5d5114bbd927d5d",
            "6bbab0b49cae4de2b0a0676246657b65"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d297b7823145188a476c7d9c20b073"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6bc89f0227f47f59bcd31a8f3b866f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7d7a7e00cb42e8b5d5114bbd927d5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bbab0b49cae4de2b0a0676246657b65"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_mask = []\n",
        "labels = torch.tensor(train_data[['winner_model_a', 'winner_model_b', 'winner_tie']].values)\n",
        "labels = labels.long()\n",
        "\n",
        "sep_id = tokenizer.sep_token_id\n",
        "sep = tokenizer.decode(sep_id)\n",
        "\n",
        "for s1, s2, s3 in zip(train_data.prompt, train_data.response_a, train_data.response_b):\n",
        "    concat = s1 + sep + s2 + sep + s3\n",
        "    tokens = tokenizer(concat, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
        "    input_ids.append(tokens['input_ids'])\n",
        "    attention_mask.append(tokens['attention_mask'])\n",
        "\n",
        "attention_mask_pt = torch.cat(attention_mask, dim=0)\n",
        "input_ids_pt = torch.cat(input_ids, dim=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:38:43.660732Z",
          "iopub.execute_input": "2024-12-29T13:38:43.660966Z",
          "iopub.status.idle": "2024-12-29T13:40:34.511444Z",
          "shell.execute_reply.started": "2024-12-29T13:38:43.660946Z",
          "shell.execute_reply": "2024-12-29T13:40:34.510413Z"
        },
        "id": "I-oTNHhNG_7T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask_pt = attention_mask_pt.long()\n",
        "input_ids_pt = input_ids_pt.long()\n",
        "labels = torch.argmax(labels.long(), dim=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.512423Z",
          "iopub.execute_input": "2024-12-29T13:40:34.512954Z",
          "iopub.status.idle": "2024-12-29T13:40:34.530514Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.51293Z",
          "shell.execute_reply": "2024-12-29T13:40:34.529594Z"
        },
        "id": "nNTkY2oWG_7T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.utils.data.TensorDataset(input_ids_pt, attention_mask_pt, labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.531946Z",
          "iopub.execute_input": "2024-12-29T13:40:34.532193Z",
          "iopub.status.idle": "2024-12-29T13:40:34.536845Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.532173Z",
          "shell.execute_reply": "2024-12-29T13:40:34.535986Z"
        },
        "id": "LaX6NbckG_7T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "(len(train_dataset) + len(val_dataset)) == len(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.538205Z",
          "iopub.execute_input": "2024-12-29T13:40:34.538502Z",
          "iopub.status.idle": "2024-12-29T13:40:34.561954Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.538473Z",
          "shell.execute_reply": "2024-12-29T13:40:34.561275Z"
        },
        "id": "OQCKMk3SG_7T",
        "outputId": "7a372e6e-d4cd-4859-d0b4-082218bcc257"
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.562636Z",
          "iopub.execute_input": "2024-12-29T13:40:34.562837Z",
          "iopub.status.idle": "2024-12-29T13:40:34.567281Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.562818Z",
          "shell.execute_reply": "2024-12-29T13:40:34.566415Z"
        },
        "id": "E8ji7jdUG_7U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7IWKyFr_G_7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_class):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained('google-bert/bert-base-uncased',\n",
        "                                              attention_probs_dropout_prob=0.1,\n",
        "                                              hidden_dropout_prob=0.1\n",
        "                                             )\n",
        "        self.fc = nn.Linear(self.bert.config.hidden_size, num_class)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs_bert = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
        "        pooler_output = outputs_bert['pooler_output']\n",
        "        output = self.fc(pooler_output)\n",
        "\n",
        "        logits = self.fc(pooler_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {\"logits\": logits, \"loss\": loss}\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.568083Z",
          "iopub.execute_input": "2024-12-29T13:40:34.568343Z",
          "iopub.status.idle": "2024-12-29T13:40:34.579162Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.568323Z",
          "shell.execute_reply": "2024-12-29T13:40:34.578285Z"
        },
        "id": "9_bOxKl5G_7U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Loop"
      ],
      "metadata": {
        "id": "SmSBnLIFG_7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(num_class=3)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:34.580069Z",
          "iopub.execute_input": "2024-12-29T13:40:34.58039Z",
          "iopub.status.idle": "2024-12-29T13:40:38.115821Z",
          "shell.execute_reply.started": "2024-12-29T13:40:34.580358Z",
          "shell.execute_reply": "2024-12-29T13:40:38.11514Z"
        },
        "id": "6IbpVLsZG_7V",
        "outputId": "df11a3a4-4960-4ca9-de68-695215a9b8c5",
        "colab": {
          "referenced_widgets": [
            "055d9bff843042d08e390ddc6ca59750"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "055d9bff843042d08e390ddc6ca59750"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr=2e-5,\n",
        "                              eps=1e-8,\n",
        "                              weight_decay=0.01)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:38.118004Z",
          "iopub.execute_input": "2024-12-29T13:40:38.118602Z",
          "iopub.status.idle": "2024-12-29T13:40:38.529378Z",
          "shell.execute_reply.started": "2024-12-29T13:40:38.118569Z",
          "shell.execute_reply": "2024-12-29T13:40:38.528676Z"
        },
        "id": "bE-BJwXoG_7V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_acc(predictions, labels):\n",
        "    return accuracy_score(labels, predictions)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:38.530227Z",
          "iopub.execute_input": "2024-12-29T13:40:38.530463Z",
          "iopub.status.idle": "2024-12-29T13:40:38.533934Z",
          "shell.execute_reply.started": "2024-12-29T13:40:38.530444Z",
          "shell.execute_reply": "2024-12-29T13:40:38.533209Z"
        },
        "id": "8ZUeDpd8G_7V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "label = next(iter(train_loader))[2]\n",
        "label"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:38.534746Z",
          "iopub.execute_input": "2024-12-29T13:40:38.535017Z",
          "iopub.status.idle": "2024-12-29T13:40:38.559519Z",
          "shell.execute_reply.started": "2024-12-29T13:40:38.534989Z",
          "shell.execute_reply": "2024-12-29T13:40:38.558654Z"
        },
        "id": "rvhQIcbBG_7V",
        "outputId": "2ab10f3f-27ce-4404-b2eb-73cb29a9c9f8"
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 1, 2, 2, 2, 0, 1, 2, 2, 2, 1, 1, 2, 2, 0,\n        0, 1, 1, 1, 1, 0, 0, 1])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        inpt_ids = batch[0].to(device)\n",
        "        attent_mask = batch[1].to(device)\n",
        "        label = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(input_ids=inpt_ids, attention_mask=attent_mask, labels=label)\n",
        "        loss = output['loss']\n",
        "        logits = output['logits']\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        all_predictions.extend(preds)\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "    acc = compute_acc(all_predictions, all_labels)\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print(f\"  Training loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Training accuracy: {acc:.4f}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_val_predictions = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs['loss']\n",
        "            logits = outputs['logits']\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            all_val_predictions.extend(preds)\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_acc = compute_acc(all_val_predictions, all_val_labels)\n",
        "    print(f\"  Validation loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Validation accuracy: {val_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-29T13:40:41.107177Z",
          "iopub.execute_input": "2024-12-29T13:40:41.107494Z"
        },
        "id": "r_9b7sr6G_7W",
        "outputId": "c49f0d53-1155-4757-816a-a41fa0bef7fa",
        "colab": {
          "referenced_widgets": [
            "ab6fa54a8be6457e8db06a2857942370",
            "2cdfdddbc1bf440abb4f1eb0e7d297ba",
            "91bec5395a534d7da4e91e52a7288d7f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1437 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab6fa54a8be6457e8db06a2857942370"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/3\n  Training loss: 1.1013\n  Training accuracy: 0.3432\n  Validation loss: 1.1026\n  Validation accuracy: 0.3406\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1437 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cdfdddbc1bf440abb4f1eb0e7d297ba"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/3\n  Training loss: 1.0891\n  Training accuracy: 0.3703\n  Validation loss: 1.0818\n  Validation accuracy: 0.3788\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1437 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91bec5395a534d7da4e91e52a7288d7f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/3\n  Training loss: 1.0767\n  Training accuracy: 0.3933\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q3S6YbzNG_7W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "id": "PG7vpaKqG_7X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "O831vi0VG_7X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ih9IY_NSG_7X"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}